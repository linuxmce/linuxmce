#! /bin/sh /usr/share/dpatch/dpatch-run
## 11_ofdb_r16988_r16995.dpatch by laga <>
##
## All lines beginning with `## DP:' are a description of the patch.
## DP: Backport r16988 and r16995 from MythPlugins trunk (thanks awithers)
## DP: Also set sys.path to account for recent python-xml changes

@DPATCH@
diff -urNad mythplugins-0.21.0+fixes17416~/mythvideo/mythvideo/scripts/ofdb.py mythplugins-0.21.0+fixes17416/mythvideo/mythvideo/scripts/ofdb.py
--- mythplugins-0.21.0+fixes17416~/mythvideo/mythvideo/scripts/ofdb.py	2008-06-01 18:08:32.000000000 -0500
+++ mythplugins-0.21.0+fixes17416/mythvideo/mythvideo/scripts/ofdb.py	2008-06-01 18:10:27.000000000 -0500
@@ -40,11 +40,17 @@
 URL_BASE="http://www.ofdb.de"
 DUMP_RESPONSE=False
 
-ofdb_version = "0.2"
+ofdb_version = "0.3"
 mythtv_version = "0.21"
 
 def comment_out(str):
-	print("# %s" % (str,))
+	s = str
+	try:
+		s = unicode(str, "utf8")
+	except:
+		pass
+
+	print("# %s" % (s,))
 
 def debug_out(str):
 	if VERBOSE:
@@ -52,12 +58,27 @@
 
 def response_out(str):
 	if DUMP_RESPONSE:
-		print(str)
+		s = str
+		try:
+			s = unicode(str, "utf8")
+		except:
+			pass
+
+		print(s)
 
 def print_exception(str):
 	for line in str.splitlines():
 		comment_out(line)
 
+def _xmlprep(content):
+	"""Removes any HTML tags that just confuse the parser."""
+
+	pat = re.compile(r'<\s*meta.*?>', re.M)
+	ret = pat.sub('', content)
+	pat = re.compile(r'<\s*script.*?<\s*/script\s*>', re.M | re.S)
+	return pat.sub('', ret)
+
+
 def _myth_url_get(url, data = None, as_post = False):
 	extras = ['ofdb', ofdb_version]
 
@@ -108,10 +129,12 @@
 	if m:
 		charset = m.group(1)
 		debug_out("Page charset reported as %s" % (charset))
-		content = unicode(content, charset)
+		# The page lies about encoding (often using two character
+		# encodings on the same page).
+		content = _xmlprep(unicode(content, charset, 'replace')).encode("utf8")
 	else:
 		# hope it is ascii
-		content = unicode(content)
+		content = _xmlprep(unicode(content, errors='replace')).encode("utf8")
 
 	response_out(content)
 	return (rc, content)
@@ -124,7 +147,7 @@
 		ret = t
 		if m:
 			ret = m.group(1)
-		return ret.strip()
+		return ret.strip().encode("utf8")
 
 	try:
 		data = {
@@ -139,7 +162,7 @@
 			data, True)
 
 		reader = HtmlLib.Reader()
-		doc = reader.fromString(content)
+		doc = reader.fromString(content, charset='utf8')
 
 		nodes = xpath.Evaluate("//A[starts-with(@href, 'film/')]",
 				doc.documentElement)
@@ -160,10 +183,11 @@
 	"""Returns the OFDb film page as an XML document."""
 	debug_out("Starting search for %s '%s'" % (context, uid))
 
-	(rc, content) = ofdb_url_get(urlparse.urljoin(URL_BASE, "film/%s" % (uid)))
+	(rc, content) = ofdb_url_get(urlparse.urljoin(URL_BASE,
+		"film/%s" % (uid.encode("utf8"),)))
 
 	reader = HtmlLib.Reader()
-	return reader.fromString(content)
+	return reader.fromString(content, charset='utf8')
 
 class NoIMDBURL(Exception):
 	pass
@@ -281,10 +305,10 @@
 
 			debug_out("Looking for plot...")
 			(rc, content) = ofdb_url_get(urlparse.urljoin(URL_BASE,
-				"plot/%s" % sid))
+				"plot/%s" % sid.encode("utf8")))
 
 			reader = HtmlLib.Reader()
-			doc = reader.fromString(content)
+			doc = reader.fromString(content, charset='utf8')
 
 			data['plot'] = unicode(all_text_children(doc.documentElement,
 					"//FONT[@class='Blocksatz']"))
@@ -297,7 +321,7 @@
 			debug_out("Looking for other info %s..." % (alturl))
 			(rc, content) = ofdb_url_get(alturl)
 			reader = HtmlLib.Reader()
-			doc = reader.fromString(content)
+			doc = reader.fromString(content, charset='utf8')
 
 			data['release_date'] = direct_value(doc.documentElement, "//DIV[@class='info']/H5[starts-with(., 'Premierendatum')]/../child::text()[2]")
 			data['runtime'] = direct_value(doc.documentElement, u"//DIV[@class='info']/H5[starts-with(., 'L\u00E4nge')]/../child::text()[2]").split()[0]
@@ -356,7 +380,7 @@
 				"title/tt%s/posters" % (id)))
 
 			reader = HtmlLib.Reader()
-			doc = reader.fromString(content)
+			doc = reader.fromString(content, charset='utf8')
 
 			nodes = xpath.Evaluate("//TABLE[starts-with(@background, 'http://posters.imdb.com/posters/')]", doc.documentElement)
 			for i in nodes:
@@ -370,7 +394,7 @@
 					base = nodes[0].getAttributeNS(EMPTY_NAMESPACE, 'href')
 					(rc, content) = ofdb_url_get(base)
 					reader = HtmlLib.Reader()
-					doc = reader.fromString(content)
+					doc = reader.fromString(content, charset='utf8')
 					nodes = xpath.Evaluate(
 							"//IMG[starts-with(@SRC, 'posters/')]",
 							doc.documentElement)
@@ -426,11 +450,14 @@
 	DUMP_RESPONSE = options.dump_response
 
 	if options.title_search:
-		search_title(options.title_search)
+		search_title(unicode(options.title_search, "utf8"))
 	elif options.data_search:
-		search_data(options.data_search, options.ratings_from)
+		rf = options.ratings_from
+		if rf:
+			rf = unicode(rf, "utf8")
+		search_data(unicode(options.data_search, "utf8"), rf)
 	elif options.poster_search:
-		search_poster(options.poster_search)
+		search_poster(unicode(options.poster_search, "utf8"))
 	else:
 		parser.print_usage()
 		sys.exit(1)
